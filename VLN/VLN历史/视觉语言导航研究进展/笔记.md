视觉语言导航：是智能体在第一视角下，基于真实环境下的全景图，综合处理指令和视觉信息并进行推理的多模态任务。



Anderson等人是视觉语言导航的开山鼻祖，公开了相应真实环境的数据集Room-to-Room(R2R)数据集，在Matterport3D模拟器中完成了导航任务的仿真。



由于MatterPort3D平台环境本身的约束，Facebook AI实验室在2019年提出Habitat平台，和Shen等在2020年提出iGibson平台，支持连续动作模拟器的推出推动了低级动作空间方面的研究。



常用的模型为：监督学习和强化学习